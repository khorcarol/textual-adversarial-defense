{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94716777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stk31/textual-adversarial-defense/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama 7B model and tokenizer...\n",
      "CUDA Available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stk31/textual-adversarial-defense/.venv/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:1041: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 7B model loaded successfully!\n",
      "Model device: cuda:0\n",
      "Model dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"Orkhan/llama-2-7b-absa\"\n",
    "\n",
    "print(\"Loading Llama 7B model and tokenizer...\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "try:\n",
    "    llama_tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "    \n",
    "    # Try loading on GPU first, fall back to CPU if issues\n",
    "    try:\n",
    "        llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"GPU loading failed ({e}), falling back to CPU...\")\n",
    "        llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=\"cpu\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "    \n",
    "    print(\"Llama 7B model loaded successfully!\")\n",
    "    \n",
    "    # Set pad token\n",
    "    if llama_tokenizer.pad_token is None:\n",
    "        llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "    \n",
    "    device = next(llama_model.parameters()).device\n",
    "    print(f\"Model device: {device}\")\n",
    "    print(f\"Model dtype: {next(llama_model.parameters()).dtype}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"You may need to authenticate with Hugging Face first:\")\n",
    "    print(\"  huggingface-cli login\")\n",
    "    \n",
    "    \n",
    "def get_llama_sentiment(text, max_length=512):\n",
    "    \"\"\"\n",
    "    Get sentiment classification from Llama 7B using prompt-based approach.\n",
    "    Returns sentiment label (Positive/Negative/Neutral) and confidence score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Truncate text to max_length characters\n",
    "        text = text[:max_length]\n",
    "        \n",
    "        # Create a sentiment analysis prompt\n",
    "        prompt = f\"\"\"Classify the sentiment of the following text.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = llama_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Get device and move inputs\n",
    "        device = next(llama_model.parameters()).device\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs.get('attention_mask').to(device) if 'attention_mask' in inputs else None\n",
    "        \n",
    "        # Ensure token ids are valid\n",
    "        if input_ids.max() >= llama_model.config.vocab_size:\n",
    "            print(f\"Warning: token id {input_ids.max()} >= vocab size {llama_model.config.vocab_size}\")\n",
    "        \n",
    "        # Generate response with conservative settings\n",
    "        with torch.no_grad():\n",
    "            outputs = llama_model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=5,\n",
    "                min_new_tokens=1,\n",
    "                temperature=1.0,\n",
    "                top_p=0.9,\n",
    "                top_k=50,\n",
    "                do_sample=False,  # Use greedy decoding\n",
    "                pad_token_id=llama_tokenizer.eos_token_id,\n",
    "                eos_token_id=llama_tokenizer.eos_token_id,\n",
    "                use_cache=True\n",
    "            )\n",
    "        \n",
    "        # Decode the response\n",
    "        \n",
    "        response = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = response[len(prompt):].strip().lower()\n",
    "\n",
    "        # Classify sentiment based on keywords\n",
    "        if any(word in response for word in [\"positive\", \"good\", \"great\", \"excellent\", \"wonderful\", \"amazing\", \"love\"]):\n",
    "            sentiment = \"POSITIVE\"\n",
    "        elif any(word in response for word in [\"negative\", \"bad\", \"poor\", \"awful\", \"terrible\", \"hate\", \"worst\"]):\n",
    "            sentiment = \"NEGATIVE\"\n",
    "        else:\n",
    "            sentiment = \"NEUTRAL\"\n",
    "         \n",
    "        return sentiment\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_llama_sentiment: {type(e).__name__}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return \"NEUTRAL\", 0.5\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing Llama sentiment classification...\")\n",
    "test_text = \"This movie was thoughtful\"\n",
    "sentiment = get_llama_sentiment(test_text)\n",
    "print(f\"Text: {test_text}\\nPredicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67e7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Llama sentiment classification...\n",
      "Text: This movie was thoughtful\n",
      "Predicted Sentiment: NEUTRAL\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b825bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Bidi override characters\n",
    "LRO = chr(0x202D)  # Left-to-Right Override\n",
    "RLO = chr(0x202E)  # Right-to-Left Override\n",
    "LRI = chr(0x2066)  # Left-to-Right Isolate\n",
    "RLI = chr(0x2067)  # Right-to-Left Isolate\n",
    "PDI = chr(0x2069)  # Pop Directional Isolate\n",
    "PDF = chr(0x202C)  # Pop Directional Formatting\n",
    "\n",
    "\n",
    "\n",
    "class TagAttack:\n",
    "    def __init__(self, perturbation_budget, tags= [0xE0001,*range(0xE0020, 0xE007F+1)]):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "        self.tags = tags\n",
    "\n",
    "    def perturb(self, text):\n",
    "        \"\"\"\n",
    "        Insert random Unicode tag characters into text, treating each\n",
    "        Unicode codepoint as a single character.\n",
    "        \"\"\"\n",
    "        # Convert string to list of codepoints\n",
    "        codepoints = [ord(c) for c in text]\n",
    "\n",
    "        for i in range(self.perturbation_budget):\n",
    "            # Choose random position in codepoint list\n",
    "            rand_index = random.randrange(len(codepoints) + 1)  # +1 to allow appending\n",
    "            rand_tag = random.choice(self.tags)\n",
    "\n",
    "            # Insert the tag codepoint at the chosen position\n",
    "            codepoints.insert(rand_index, rand_tag)\n",
    "\n",
    "        # Convert back to string\n",
    "        return \"\".join(chr(cp) for cp in codepoints)\n",
    "\n",
    "\n",
    "class VariationSelectorAttack:\n",
    "    def __init__(self, perturbation_budget, variation_selectors = [*range(0xFE00, 0xFE0F + 1), *range(0xE0100, 0xE01EF + 1)]):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "        self.variation_selectors = variation_selectors\n",
    "\n",
    "    def perturb(self, text):\n",
    "        # Convert string to list of codepoints\n",
    "        codepoints = [ord(c) for c in text]\n",
    "\n",
    "        for _ in range(self.perturbation_budget):\n",
    "            # Choose random position in codepoint list\n",
    "            rand_index = random.randrange(len(codepoints) + 1)  # allow append\n",
    "            rand_vs = random.choice(self.variation_selectors)\n",
    "\n",
    "            # Insert the variation selector codepoint\n",
    "            codepoints.insert(rand_index, rand_vs)\n",
    "\n",
    "        # Convert back to string\n",
    "        return \"\".join(chr(cp) for cp in codepoints)\n",
    "\n",
    "\n",
    "class InvisibleCharAttack:\n",
    "    def __init__(self, perturbation_budget, invisible_chars=[0x200B, 0x200C, 0x200D, 0x2060, 0xFEFF]):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "        self.invisible_chars = invisible_chars\n",
    "\n",
    "    def perturb(self, text):\n",
    "        # Convert string to list of codepoints\n",
    "        codepoints = [ord(c) for c in text]\n",
    "\n",
    "        for _ in range(self.perturbation_budget):\n",
    "            # Choose random position in codepoint list\n",
    "            rand_index = random.randrange(len(codepoints) + 1)  # allow append\n",
    "            rand_invisible = random.choice(self.invisible_chars)\n",
    "\n",
    "            # Insert the invisible character\n",
    "            codepoints.insert(rand_index, rand_invisible)\n",
    "\n",
    "        # Convert back to string\n",
    "        return \"\".join(chr(cp) for cp in codepoints)\n",
    "\n",
    "\n",
    "class HomoglyphAttack:\n",
    "    def __init__(self, perturbation_budget, homoglyph_map_path='/home/stk31/textual-adversarial-defense/utils/homoglyphs/intentional.json'):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "        with open(homoglyph_map_path, 'r') as f:\n",
    "            hex_map = json.load(f)\n",
    "        # Convert hex strings to codepoints\n",
    "        self.homoglyph_map = {int(k, 16): int(v, 16) for k, v in hex_map.items()}\n",
    "        self.homoglyph_chars = list(self.homoglyph_map.keys())\n",
    "\n",
    "    def perturb(self, text):\n",
    "        # Convert string to list of codepoints\n",
    "        codepoints = [ord(c) for c in text]\n",
    "        \n",
    "        # Replace random characters with homoglyphs\n",
    "        indices = list(range(len(codepoints)))\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        for i in indices[:min(self.perturbation_budget, len(indices))]:\n",
    "            cp = codepoints[i]\n",
    "            # If character has a homoglyph, replace it\n",
    "            if cp in self.homoglyph_map:\n",
    "                codepoints[i] = self.homoglyph_map[cp]\n",
    "\n",
    "        # Convert back to string\n",
    "        return \"\".join(chr(cp) for cp in codepoints)\n",
    "\n",
    "\n",
    "class DeletionCharAttack:\n",
    "    def __init__(self, perturbation_budget, deletion_char=0x8):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "        self.deletion_char = deletion_char  # Backspace character\n",
    "        self.ascii_chars = list(range(32, 127))  # Printable ASCII characters\n",
    "\n",
    "    def perturb(self, text):\n",
    "        # Convert string to list of codepoints\n",
    "        codepoints = [ord(c) for c in text]\n",
    "        \n",
    "        for _ in range(self.perturbation_budget):\n",
    "            # Choose random position in codepoint list\n",
    "            rand_index = random.randrange(len(codepoints) + 1)  # allow append\n",
    "            # Insert random ASCII character followed by deletion character\n",
    "            rand_ascii = random.choice(self.ascii_chars)\n",
    "            codepoints.insert(rand_index, rand_ascii)\n",
    "            codepoints.insert(rand_index + 1, self.deletion_char)\n",
    "\n",
    "        # Convert back to string\n",
    "        return \"\".join(chr(cp) for cp in codepoints)\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Bidi override characters\n",
    "RLO = chr(0x202E)   # Right-to-Left Override\n",
    "PDF = chr(0x202C)   # Pop Directional Formatting\n",
    "RLI = chr(0x2067)   # Right-to-Left Isolate\n",
    "PDI = chr(0x2069)   # Pop Directional Isolate\n",
    "LRO = chr(0x202D)   # Left-to-Right Override\n",
    "LRI = chr(0x2066)   # Left-to-Right Isolate\n",
    "# ... (Other classes like Swap, TagAttack, etc., remain unchanged) ...\n",
    "\n",
    "class BidiAttack:\n",
    "    def __init__(self, perturbation_budget):\n",
    "        self.perturbation_budget = perturbation_budget\n",
    "    \n",
    "    def _encode_swap_spoof(self, one, two):\n",
    "        \"\"\"\n",
    "        Creates a string that contains the characters 'two' followed by 'one' \n",
    "        in the data, but is displayed as 'one' followed by 'two'.\n",
    "        Sequence: RLO + two + one + PDF\n",
    "        \"\"\"\n",
    "        # LRO, LRI, RLO, LRI, el.two, PDI, LRI, el.one, PDI, PDF, PDI, PDF\n",
    "        \n",
    "        # Display order is visually reversed by RLO\n",
    "        return LRO + LRI+ RLO + LRI + two + PDI + LRI + one + PDI + PDF + PDI + PDF\n",
    "\n",
    "    def perturb(self, text):\n",
    "        \"\"\"\n",
    "        Swaps random *non-overlapping* adjacent character pairs in the \n",
    "        underlying data and uses Bidi controls to visually reverse the swap.\n",
    "        \"\"\"\n",
    "        chars = list(text)\n",
    "        n = len(chars)\n",
    "        \n",
    "        possible_start_indices = list(range(n - 1))\n",
    "        random.shuffle(possible_start_indices)\n",
    "        \n",
    "        swaps_to_make = set()\n",
    "        swaps_remaining = self.perturbation_budget\n",
    "        \n",
    "        # Select non-overlapping swap positions\n",
    "        for i in possible_start_indices:\n",
    "            if i not in swaps_to_make and i + 1 not in swaps_to_make:\n",
    "                if swaps_remaining > 0:\n",
    "                    swaps_to_make.add(i)\n",
    "                    # Add the next index to the set to prevent it from starting a new swap\n",
    "                    swaps_to_make.add(i + 1) \n",
    "                    swaps_remaining -= 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        swaps_to_make = []\n",
    "        available_positions = list(range(n - 1))\n",
    "        random.shuffle(available_positions)\n",
    "        \n",
    "        processed_indices = set()\n",
    "        \n",
    "        for pos in available_positions:\n",
    "            # A swap starts at 'pos' and involves 'pos' and 'pos + 1'\n",
    "            if pos not in processed_indices and (pos + 1) not in processed_indices:\n",
    "                if len(swaps_to_make) < self.perturbation_budget:\n",
    "                    swaps_to_make.append(pos)\n",
    "                    # Mark both characters in the pair as 'used'\n",
    "                    processed_indices.add(pos)\n",
    "                    processed_indices.add(pos + 1)\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        # Build perturbed text\n",
    "        perturbed_text = \"\"\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            if i in swaps_to_make and chars[i].isalpha() and chars[i + 1].isalpha():\n",
    "                # This index starts a swap\n",
    "                char_one = chars[i]\n",
    "                char_two = chars[i + 1]\n",
    "                \n",
    "                # Data: two, one (visually displays as: one, two)\n",
    "                spoofed_pair = self._encode_swap_spoof(char_one, char_two)\n",
    "                perturbed_text += spoofed_pair\n",
    "                \n",
    "                # Advance counter by 2 since both characters were processed\n",
    "                i += 2 \n",
    "            else:\n",
    "                # Add normal character\n",
    "                perturbed_text += chars[i]\n",
    "                i += 1\n",
    "                \n",
    "        return perturbed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f3f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import _pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0}\n",
      "{'sentence': 'contains no wit , only labored gags ', 'label': 0, 'idx': 1}\n",
      "{'sentence': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': 1, 'idx': 2}\n",
      "{'sentence': 'remains utterly satisfied to remain the same throughout ', 'label': 0, 'idx': 3}\n",
      "{'sentence': 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ', 'label': 0, 'idx': 4}\n",
      "{'sentence': \"that 's far too tragic to merit such superficial treatment \", 'label': 0, 'idx': 5}\n",
      "{'sentence': 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ', 'label': 1, 'idx': 6}\n",
      "{'sentence': 'of saucy ', 'label': 1, 'idx': 7}\n",
      "{'sentence': \"a depressed fifteen-year-old 's suicidal poetry \", 'label': 0, 'idx': 8}\n",
      "{'sentence': \"are more deeply thought through than in most ` right-thinking ' films \", 'label': 1, 'idx': 9}\n",
      "Llama SST-2 Accuracy: 9/10 = 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Testing Llama sentiment classification...\n",
    "sst2_llama = load_dataset(\"glue\", \"sst2\", split=\"train\")\n",
    "data = sst2_llama.select(range(100)).to_list()\n",
    "\n",
    "accurate = 0\n",
    "for row in data:\n",
    "    print(row)\n",
    "    text = row[\"sentence\"]\n",
    "    label = row[\"label\"]\n",
    "    sentiment = get_llama_sentiment(text)\n",
    "    if sentiment == \"POSITIVE\" and label == 1:\n",
    "        accurate += 1\n",
    "    elif sentiment == \"NEGATIVE\" and label == 0:\n",
    "        accurate += 1\n",
    "    \n",
    "print(f\"Llama SST-2 Accuracy: {accurate}/{len(data)} = {accurate/len(data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9aeff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LLAMA 7B SENTIMENT CLASSIFICATION ATTACK EXPERIMENT\n",
      "================================================================================\n",
      "\n",
      "Loading SST-2 dataset...\n",
      "Testing 50 samples across budgets: [5, 10, 15, 20]\n",
      "\n",
      "Getting baseline predictions for original texts...\n",
      "  Sample 1: it 's a charming and often affecting journey . ... -> POSITIVE\n",
      "  Sample 2: unflinchingly bleak and desperate ... -> NEGATIVE\n",
      "  Sample 3: allows us to hope that nolan is poised to embark a... -> POSITIVE\n",
      "  Sample 4: the acting , costumes , music , cinematography and... -> POSITIVE\n",
      "  Sample 5: it 's slow -- very , very slow . ... -> NEGATIVE\n",
      "  Sample 6: although laced with humor and a few fanciful touch... -> POSITIVE\n",
      "  Sample 7: a sometimes tedious film . ... -> NEGATIVE\n",
      "  Sample 8: or doing last year 's taxes with your ex-wife . ... -> NEGATIVE\n",
      "  Sample 9: you do n't have to know about music to appreciate ... -> POSITIVE\n",
      "  Sample 10: in exactly 89 minutes , most of which passed as sl... -> NEGATIVE\n",
      "  Sample 11: the mesmerizing performances of the leads keep the... -> POSITIVE\n",
      "  Sample 12: it takes a strange kind of laziness to waste the t... -> NEGATIVE\n",
      "  Sample 13: ... the film suffers from a lack of humor ( someth... -> NEGATIVE\n",
      "  Sample 14: we root for ( clara and paul ) , even like them , ... -> NEGATIVE\n",
      "  Sample 15: even horror fans will most likely not find what th... -> NEGATIVE\n",
      "  Sample 16: a gorgeous , high-spirited musical from india that... -> POSITIVE\n",
      "  Sample 17: the emotions are raw and will strike a nerve with ... -> NEGATIVE\n",
      "  Sample 18: audrey tatou has a knack for picking roles that ma... -> POSITIVE\n",
      "  Sample 19: ... the movie is just a plain old monster . ... -> NEGATIVE\n",
      "  Sample 20: in its best moments , resembles a bad high school ... -> NEGATIVE\n",
      "  Sample 21: pumpkin takes an admirable look at the hypocrisy o... -> NEGATIVE\n",
      "  Sample 22: the iditarod lasts for days - this just felt like ... -> NEGATIVE\n",
      "  Sample 23: holden caulfield did it better . ... -> POSITIVE\n",
      "  Sample 24: a delectable and intriguing thriller filled with s... -> POSITIVE\n",
      "  Sample 25: seldom has a movie so closely matched the spirit o... -> POSITIVE\n",
      "  Sample 26: nicks , seemingly uncertain what 's going to make ... -> NEGATIVE\n",
      "  Sample 27: the action switches between past and present , but... -> NEGATIVE\n",
      "  Sample 28: it 's an offbeat treat that pokes fun at the democ... -> POSITIVE\n",
      "  Sample 29: it 's a cookie-cutter movie , a cut-and-paste job ... -> NEGATIVE\n",
      "  Sample 30: i had to look away - this was god awful . ... -> NEGATIVE\n",
      "  Sample 31: thanks to scott 's charismatic roger and eisenberg... -> POSITIVE\n",
      "  Sample 32: ... designed to provide a mix of smiles and tears ... -> NEGATIVE\n",
      "  Sample 33: a gorgeous , witty , seductive movie . ... -> POSITIVE\n",
      "  Sample 34: if the movie succeeds in instilling a wary sense o... -> NEGATIVE\n",
      "  Sample 35: it does n't believe in itself , it has no sense of... -> NEGATIVE\n",
      "  Sample 36: a sequence of ridiculous shoot - 'em - up scenes .... -> NEGATIVE\n",
      "  Sample 37: the weight of the piece , the unerring professiona... -> POSITIVE\n",
      "  Sample 38: ( w ) hile long on amiable monkeys and worthy envi... -> NEGATIVE\n",
      "  Sample 39: as surreal as a dream and as detailed as a photogr... -> POSITIVE\n",
      "  Sample 40: escaping the studio , piccoli is warmly affecting ... -> POSITIVE\n",
      "  Sample 41: there 's ... tremendous energy from the cast , a s... -> POSITIVE\n",
      "  Sample 42: this illuminating documentary transcends our preco... -> POSITIVE\n",
      "  Sample 43: the subtle strength of `` elling '' is that it nev... -> POSITIVE\n",
      "  Sample 44: holm ... embodies the character with an effortless... -> POSITIVE\n",
      "  Sample 45: the title not only describes its main characters ,... -> NEGATIVE\n",
      "  Sample 46: it offers little beyond the momentary joys of pret... -> NEGATIVE\n",
      "  Sample 47: a synthesis of cliches and absurdities that seems ... -> NEGATIVE\n",
      "  Sample 48: a subtle and well-crafted ( for the most part ) ch... -> POSITIVE\n",
      "  Sample 49: has a lot of the virtues of eastwood at his best .... -> POSITIVE\n",
      "  Sample 50: it 's hampered by a lifetime-channel kind of plot ... -> NEGATIVE\n",
      "\n",
      "Baseline predictions: ['POSITIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE', 'NEGATIVE']\n",
      "\n",
      "\n",
      "=== Budget: 5 ===\n",
      "  Testing tag attack... Attack Success: 4.0% | Defense Recovery: 100.0%\n",
      "  Testing invisible attack... Attack Success: 2.0% | Defense Recovery: 100.0%\n",
      "  Testing deletion attack... Attack Success: 2.0% | Defense Recovery: 100.0%\n",
      "  Testing bidi attack... Attack Success: 14.0% | Defense Recovery: 86.0%\n",
      "  Testing combined attack... Attack Success: 22.0% | Defense Recovery: 100.0%\n",
      "\n",
      "=== Budget: 10 ===\n",
      "  Testing tag attack... Attack Success: 6.0% | Defense Recovery: 100.0%\n",
      "  Testing invisible attack... Attack Success: 2.0% | Defense Recovery: 100.0%\n",
      "  Testing deletion attack... Attack Success: 8.0% | Defense Recovery: 100.0%\n",
      "  Testing bidi attack... Attack Success: 28.0% | Defense Recovery: 74.0%\n",
      "  Testing combined attack... Attack Success: 42.0% | Defense Recovery: 100.0%\n",
      "\n",
      "=== Budget: 15 ===\n",
      "  Testing tag attack... Attack Success: 16.0% | Defense Recovery: 100.0%\n",
      "  Testing invisible attack... Attack Success: 8.0% | Defense Recovery: 100.0%\n",
      "  Testing deletion attack... Attack Success: 14.0% | Defense Recovery: 100.0%\n",
      "  Testing bidi attack... Attack Success: 28.0% | Defense Recovery: 72.0%\n",
      "  Testing combined attack... Attack Success: 44.0% | Defense Recovery: 100.0%\n",
      "\n",
      "=== Budget: 20 ===\n",
      "  Testing tag attack... Attack Success: 18.0% | Defense Recovery: 100.0%\n",
      "  Testing invisible attack... Attack Success: 8.0% | Defense Recovery: 100.0%\n",
      "  Testing deletion attack... Attack Success: 26.0% | Defense Recovery: 100.0%\n",
      "  Testing bidi attack... Attack Success: 42.0% | Defense Recovery: 62.0%\n",
      "  Testing combined attack... Attack Success: 48.0% | Defense Recovery: 100.0%\n",
      "\n",
      "================================================================================\n",
      "LLAMA 7B EXPERIMENT RESULTS\n",
      "================================================================================\n",
      "   model  budget    attack attack_success_rate defense_recovery_rate\n",
      "Llama-7B       5       tag                4.0%                100.0%\n",
      "Llama-7B       5 invisible                2.0%                100.0%\n",
      "Llama-7B       5  deletion                2.0%                100.0%\n",
      "Llama-7B       5      bidi               14.0%                 86.0%\n",
      "Llama-7B       5  combined               22.0%                100.0%\n",
      "Llama-7B      10       tag                6.0%                100.0%\n",
      "Llama-7B      10 invisible                2.0%                100.0%\n",
      "Llama-7B      10  deletion                8.0%                100.0%\n",
      "Llama-7B      10      bidi               28.0%                 74.0%\n",
      "Llama-7B      10  combined               42.0%                100.0%\n",
      "Llama-7B      15       tag               16.0%                100.0%\n",
      "Llama-7B      15 invisible                8.0%                100.0%\n",
      "Llama-7B      15  deletion               14.0%                100.0%\n",
      "Llama-7B      15      bidi               28.0%                 72.0%\n",
      "Llama-7B      15  combined               44.0%                100.0%\n",
      "Llama-7B      20       tag               18.0%                100.0%\n",
      "Llama-7B      20 invisible                8.0%                100.0%\n",
      "Llama-7B      20  deletion               26.0%                100.0%\n",
      "Llama-7B      20      bidi               42.0%                 62.0%\n",
      "Llama-7B      20  combined               48.0%                100.0%\n",
      "\n",
      "Results saved to llama7b_attack_defense_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLAMA 7B SENTIMENT CLASSIFICATION ATTACK EXPERIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use subset of SST-2 data for faster testing with Llama\n",
    "print(\"\\nLoading SST-2 dataset...\")\n",
    "sst2_llama = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "num_samples_llama = 50   # Smaller subset for Llama due to slower inference\n",
    "texts_llama = sst2_llama['sentence'][:num_samples_llama]\n",
    "\n",
    "# Initialize results list\n",
    "llama_results = []\n",
    "\n",
    "# Perturbation budgets to test\n",
    "budgets_llama = [5, 10, 15, 20]  # Include 0 to get baseline predictions\n",
    "\n",
    "print(f\"Testing {num_samples_llama} samples across budgets: {budgets_llama}\\n\")\n",
    "\n",
    "# Define attack types (same as before)\n",
    "attack_types_llama = ['tag', 'invisible', 'deletion', 'bidi', 'combined']\n",
    "\n",
    "# Get baseline predictions for original texts FIRST\n",
    "print(\"Getting baseline predictions for original texts...\")\n",
    "original_preds_llama = []\n",
    "\n",
    "for i, text in enumerate(texts_llama):\n",
    "    sentiment = get_llama_sentiment(text)\n",
    "    original_preds_llama.append(sentiment)\n",
    "    print(f\"  Sample {i+1}: {text[:50]}... -> {sentiment}\")\n",
    "\n",
    "print(f\"\\nBaseline predictions: {original_preds_llama}\\n\")\n",
    "\n",
    "# Process each budget (skip budget 0 in loop since we already have baseline)\n",
    "for budget in budgets_llama:\n",
    "    if budget == 0:\n",
    "        continue  # Skip budget 0, we already have baseline predictions\n",
    "    \n",
    "    print(f\"\\n=== Budget: {budget} ===\")\n",
    "    \n",
    "    # Initialize attacks\n",
    "    tag_attack_llama = TagAttack(perturbation_budget=budget)\n",
    "    invisible_attack_llama = InvisibleCharAttack(perturbation_budget=budget)\n",
    "    deletion_attack_llama = DeletionCharAttack(perturbation_budget=budget)\n",
    "    bidi_attack_llama = BidiAttack(perturbation_budget=budget)\n",
    "    \n",
    "    # Test each attack type\n",
    "    for attack_name in attack_types_llama:\n",
    "        print(f\"  Testing {attack_name} attack...\", end=\" \", flush=True)\n",
    "        \n",
    "        perturbed_preds = []\n",
    "        perturbed_confs = []\n",
    "        sanitized_preds = []\n",
    "        sanitized_confs = []\n",
    "        \n",
    "        for text in texts_llama:\n",
    "            # Apply attack\n",
    "            if attack_name == 'tag':\n",
    "                perturbed = tag_attack_llama.perturb(text)\n",
    "            elif attack_name == 'invisible':\n",
    "                perturbed = invisible_attack_llama.perturb(text)\n",
    "            elif attack_name == 'deletion':\n",
    "                perturbed = deletion_attack_llama.perturb(text)\n",
    "            elif attack_name == 'bidi':\n",
    "                perturbed = bidi_attack_llama.perturb(text)\n",
    "            elif attack_name == 'combined':\n",
    "                perturbed = tag_attack_llama.perturb(text)\n",
    "                perturbed = invisible_attack_llama.perturb(perturbed)\n",
    "                perturbed = deletion_attack_llama.perturb(perturbed)\n",
    "                perturbed = bidi_attack_llama.perturb(perturbed)\n",
    "            \n",
    "            # Get prediction on perturbed text\n",
    "            sentiment = get_llama_sentiment(perturbed)\n",
    "            perturbed_preds.append(sentiment)\n",
    "            \n",
    "            # Apply sanitizers to the perturbed text\n",
    "            p = _pipeline.Pipeline()\n",
    "            if attack_name == 'combined':\n",
    "                p.add_bidi_sanitizer()\n",
    "                p.add_tag_sanitizer()\n",
    "                p.add_invisible_sanitizer()\n",
    "                p.add_deletion_sanitizer()\n",
    "            else:\n",
    "                # Map attack to sanitizer\n",
    "                if attack_name == 'tag':\n",
    "                    p.add_tag_sanitizer()\n",
    "                elif attack_name == 'invisible':\n",
    "                    p.add_invisible_sanitizer()\n",
    "                elif attack_name == 'deletion':\n",
    "                    p.add_deletion_sanitizer()\n",
    "                elif attack_name == 'bidi':\n",
    "                    p.add_bidi_sanitizer()\n",
    "            \n",
    "            sanitized = p.sanitize(perturbed)\n",
    "            \n",
    "            # Get prediction on sanitized text\n",
    "            sentiment = get_llama_sentiment(sanitized)\n",
    "            sanitized_preds.append(sentiment)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        attack_success_rate = sum(1 for i in range(num_samples_llama) if perturbed_preds[i] != original_preds_llama[i]) / num_samples_llama * 100\n",
    "        defense_recovery_rate = sum(1 for i in range(num_samples_llama) if sanitized_preds[i] == original_preds_llama[i]) / num_samples_llama * 100\n",
    "        \n",
    "        llama_results.append({\n",
    "            'model': 'Llama-7B',\n",
    "            'budget': budget,\n",
    "            'attack': attack_name,\n",
    "            'attack_success_rate': f\"{attack_success_rate:.1f}%\",\n",
    "            'defense_recovery_rate': f\"{defense_recovery_rate:.1f}%\",\n",
    "        })\n",
    "        \n",
    "        print(f\"Attack Success: {attack_success_rate:.1f}% | Defense Recovery: {defense_recovery_rate:.1f}%\")\n",
    "\n",
    "# Create results dataframe\n",
    "llama_results_df = pd.DataFrame(llama_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LLAMA 7B EXPERIMENT RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(llama_results_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "llama_csv_file = \"llama7b_attack_defense_results.csv\"\n",
    "llama_results_df.to_csv(llama_csv_file, index=False)\n",
    "print(f\"\\nResults saved to {llama_csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
